{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"elapsed":860,"status":"ok","timestamp":1683153481609,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"YAfl1CXOOsgt","outputId":"97571f4a-baa0-4310-d48b-3bf61167ee1e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nNOTE: For TPU only\\nMust go to Command Pallette (Cmd/Ctrl+Shift+P) and enter \"Use Fallback Runtime\" to enable running older python\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":[" \"\"\"\n"," NOTE: For TPU only\n"," Must go to Command Pallette (Cmd/Ctrl+Shift+P) and enter \"Use Fallback Runtime\" to enable running older python\n"," \"\"\"\n"," #! pip install cloud-tpu-client==0.10.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp39-cp39-linux_x86_64.whl"],"id":"YAfl1CXOOsgt"},{"cell_type":"code","execution_count":2,"metadata":{"id":"RjQdzrQaHZ_Z","executionInfo":{"status":"ok","timestamp":1683153482155,"user_tz":420,"elapsed":5,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"}}},"outputs":[],"source":[],"id":"RjQdzrQaHZ_Z"},{"cell_type":"markdown","metadata":{"id":"z1_sx-kNHfwt"},"source":["After expanding the sequence length, we quickly overran the available GPU RAM. Below, we import tools for utilizing mixed precision training to easily conserve memory. We also implemented gradient accumulation for the same purpose. "],"id":"z1_sx-kNHfwt"},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3700,"status":"ok","timestamp":1683153485851,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"ac0a684e","outputId":"72fc6652-0ed0-4084-d590-b261892f5485"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"]}],"source":["!pip install sentencepiece"],"id":"ac0a684e"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4018,"status":"ok","timestamp":1683153489862,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"321d29cd","outputId":"58940ff4-0eaf-4ae7-b757-979ebc78f2cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n"]}],"source":["!pip install transformers"],"id":"321d29cd"},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1223,"status":"ok","timestamp":1683153491074,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"9ZgKS8RSv66V"},"outputs":[],"source":["import pandas as pd"],"id":"9ZgKS8RSv66V"},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3528,"status":"ok","timestamp":1683153494596,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"CbKVAQgtnNKF","outputId":"cdcb5172-1f54-4767-f36f-d4025e3ab8e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"id":"CbKVAQgtnNKF"},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1683153494597,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"IMTJI2Fi98h0"},"outputs":[],"source":["import os\n","#assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"],"id":"IMTJI2Fi98h0"},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1683153494598,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"MbQztCxJKv78"},"outputs":[],"source":["#import torch_xla.core.xla_model as xm"],"id":"MbQztCxJKv78"},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6565,"status":"ok","timestamp":1683153501154,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"152682d8"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import random\n","import torch.nn as nn\n","\n","from torch.cuda.amp import autocast, GradScaler\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.metrics import classification_report\n","from sklearn.utils.class_weight import compute_class_weight\n","import transformers\n","from transformers import BigBirdModel, BigBirdTokenizerFast\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel, BertTokenizerFast\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"],"id":"152682d8"},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1683153501156,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"99ce5053","outputId":"b603feab-4607-4568-90bc-11d3e3481022"},"outputs":[{"output_type":"stream","name":"stdout","text":["gpu available\n"]}],"source":["#device = xm.xla_device()\n","\n","#check is gpu is available\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","    print('gpu available')\n","else:\n","    device = torch.device('cpu')\n","    print('gpu not available')"],"id":"99ce5053"},{"cell_type":"markdown","metadata":{"id":"oPYpREJfzyso"},"source":["Our first attempt involved creating full transcripts for each case and exporting them as CSVs, which we then loaded into the script as needed. This exceeded the memory limits of Google Colab's TPUs and GPUs during training. \n","\n","We then tried a similar process but with the the \"utterance\" transcripts -- essentially lengths of text spoken by one person. Here, however, the RAM limit was exceeded when using the package that creates the utterance objects. We do not know why the RAM was exceeded here given that we were able to run the package locally on machines with lower amounts of RAM. \n","\n","Our third attempt was to create a dataframe of all utterances and the associated text and export it as a csv, roughly 1.7 million lines and 0.6GB as opposed to the packages ~7.3GB. "],"id":"oPYpREJfzyso"},{"cell_type":"code","execution_count":11,"metadata":{"id":"R5w3dIS7Q3wH","executionInfo":{"status":"ok","timestamp":1683153501157,"user_tz":420,"elapsed":12,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"}}},"outputs":[],"source":["# set to run with utterances or conversations \n","utts = False"],"id":"R5w3dIS7Q3wH"},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15744,"status":"ok","timestamp":1683153516891,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"2TNPMKAA1PQz","outputId":"6c378fcf-f50a-4fb9-f88f-6cc3e33e6c8d"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-1a00a5baf015>:2: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df_utt = pd.read_csv('/content/drive/MyDrive/INFO251Final/Utterances_DataFrame.csv')\n"]}],"source":["# create dataframe of utterances by case\n","df_utt = pd.read_csv('/content/drive/MyDrive/INFO251Final/Utterances_DataFrame.csv')\n","\n","# create dataframe by conversation record\n","df_convo = pd.read_csv('/content/drive/MyDrive/INFO251Final/Outcomes_NoTranscript.csv')\n","\n","# create datafrae of Martin Quinn scores to merge with dataframes\n","martin_quinn = pd.read_csv('/content/drive/MyDrive/INFO251Final/MartinQuinnScores.csv')\n","\n","df_args = pd.read_csv('/content/drive/MyDrive/INFO251Final/ArgumentsTable.csv')"],"id":"2TNPMKAA1PQz"},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1683153516892,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"c972caa7"},"outputs":[],"source":["def clean_utts(df_utt):\n","    # updating columns\n","\n","    # rename columns\n","    df_utt = df_utt.rename(columns={'meta.votes_side': 'votes_side',\n","                                      'meta.win_side': 'win_side',\n","                                      'meta.case_id': 'case_id',\n","                                      'med': 'mq_score', \n","                                      'conversation_id': 'convo_id',\n","                                      'term_year': 'term'})\n","\n","    df_utt.term = df_utt.term.astype('int64')\n","\n","    # add MartinQuinn Scores\n","    df_utt = df_utt.merge(martin_quinn[['term', 'med']], on='term')\n","\n","    # drop unused columns\n","    # NOTE we may want to try an analysis on some of these later on\n","    df_utt = df_utt.drop(columns=['speaker', \n","                                  'reply_to', \n","                                  'timestamp', \n","                                  'meta.start_times', \n","                                  'meta.stop_times', \n","                                  'meta.speaker_type',\n","                                  'meta.side',\n","                                  'meta.timestamp',\n","                                  'vectors',\n","                                  'Unnamed: 0'])\n","\n","\n","    # add \"win_side\" to utterance dataframe\n","    \n","\n","    #df_utt.drop(columns=['Unnamed: 0'])df_utt = df_utt.merge(df_convo[['convo_id', 'win_side']], on='convo_id')\n","    df_utt = df_utt.rename(columns={'text': 'words'})\n","\n","    # Remove instances where case outcome was unknown or ????\n","    df_utt.drop(df_utt[df_utt['win_side'] == -1.0].index, inplace = True)\n","    df_utt.drop(df_utt[df_utt['win_side'] == 2.0].index, inplace = True)\n","\n","    # Remove null values from the few cases with incomplete data\n","    df_utt = df_utt.dropna()\n","\n","    return df_utt"],"id":"c972caa7"},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":1988,"status":"error","timestamp":1683153580417,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"ik__eiZQKaV9","colab":{"base_uri":"https://localhost:8080/","height":494},"outputId":"d110c4fc-9e96-4d24-c0f0-535344fb5b05"},"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'win_side'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-92e6e47336b1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_utt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_utts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_utt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-13-c79ddb533540>\u001b[0m in \u001b[0;36mclean_utts\u001b[0;34m(df_utt)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Remove instances where case outcome was unknown or ????\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mdf_utt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_utt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_utt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'win_side'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mdf_utt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_utt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_utt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'win_side'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'win_side'"]}],"source":["df_utt = clean_utts(df_utt)"],"id":"ik__eiZQKaV9"},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1683153582470,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"67OjJ2aJKrRe"},"outputs":[],"source":["def clean_convos(df_convo):\n","  # Remove instances where case outcome was unknown or ????\n","  df_convo.drop(df_convo[df_convo['win_side'] == -1.0].index, inplace = True)\n","  df_convo.drop(df_convo[df_convo['win_side'] == 2.0].index, inplace = True)\n","\n","  # convert term from object to int\n","  df_convo.term = df_convo.term.astype('int64')\n","\n","  # drop unused columns\n","  # NOTE we may want to try an analysis on some of these later on. Save memory now\n","  df_convo = df_convo.drop(columns=['Unnamed: 0', 'vectors', 'advocates', 'votes_side'])\n","\n","  # 3 cases have null data due to oddities of transcribing data pre-digital transcripts\n","  df_convo = df_convo.dropna()\n","\n","  return df_convo"],"id":"67OjJ2aJKrRe"},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1683153582938,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"5giNnmG7LWD-"},"outputs":[],"source":["df_convo = clean_convos(df_convo)"],"id":"5giNnmG7LWD-"},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1683153583986,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"9fbecbdb"},"outputs":[],"source":["# Take a sample of df_convos or df_utts to test on\n","df_test = df_convo.sample(n=7000, replace=False, random_state=12)"],"id":"9fbecbdb"},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1683153583987,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"67nzCYIP3rxV"},"outputs":[],"source":["##### Delete for now\n","del(df_utt)"],"id":"67nzCYIP3rxV"},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683153584612,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"kf6LNCHF0sGf"},"outputs":[],"source":["# create a helper function that gets a random contiguous chunk of words from a transcript\n","\n","random.seed(123)\n","\n","def get_random_chunk(text, n_mean=1500, n_stddev=75):\n","    words = text.split()\n","\n","    n = int(np.random.normal(n_mean, n_stddev))\n","    n = max(1, min(n, len(words))) # Ensure n is between 1 and the number of words in the text\n","\n","    if len(words) <= n:\n","        return text\n","\n","    start = random.randint(0, len(words) - n)\n","    end = start + n\n","    return \" \".join(words[start:end])"],"id":"kf6LNCHF0sGf"},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683153586826,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"4d267fbd"},"outputs":[],"source":["# pull transcripts for each utterance or conversation and store in \"words\" column\n","# This method separately creates the transcripts for each conversation and stores them in a \n","# separate folder for reference. Although this allowed for easy grouping by case, it \n","# overwhelmed memory allocations \n","\n","def add_transcripts(df_test, utts=False):\n","  for index, row in df_test.iterrows():\n","\n","\n","    if utts:\n","      folder_path = '/content/drive/MyDrive/INFO251Final/Trancripts_uttid_caseid/'\n","      read_path = folder_path+str(row['utt_id'])+'_'+str(row['case_id'])+'.txt'\n","\n","      transcript = open(read_path, 'r')\n","      text = transcript.read()\n","\n","      text = get_random_chunk(text)\n","      \n","      df_test.loc[index, 'words'] = text\n","\n","      transcript.close()\n","\n","    else:\n","      folder_path = '/content/drive/MyDrive/INFO251Final/Trancripts_Case_Convo/'\n","      read_path = folder_path+str(row['convo_id'])+'_'+str(row['case_id'])+'.txt'\n","\n","      transcript = open(read_path, 'r')\n","      text = transcript.read()\n","\n","      text = get_random_chunk(text)\n","\n","      df_test.at[index, 'words'] = text\n","  \n","      transcript.close()\n","\n","  return df_test\n","    "],"id":"4d267fbd"},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":240,"status":"ok","timestamp":1683153591419,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"f81S4FOJOe8h","colab":{"base_uri":"https://localhost:8080/","height":452},"outputId":"05d538be-2d1d-4592-d226-1344d81008bd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0 vectors meta.case_id  \\\n","0           0      []      1955_71   \n","1           1      []     1955_410   \n","2           2      []     1955_410   \n","3           3      []     1955_351   \n","4           4      []      1955_38   \n","\n","                                      meta.advocates  meta.win_side  \\\n","0  {'harry_f_murphy': {'side': 1, 'role': 'inferr...            0.0   \n","1  {'howard_c_westwood': {'side': 1, 'role': 'inf...            1.0   \n","2  {'howard_c_westwood': {'side': 1, 'role': 'inf...            1.0   \n","3  {'harry_d_graham': {'side': 3, 'role': 'inferr...            1.0   \n","4  {'robert_n_gorman': {'side': 3, 'role': 'infer...            0.0   \n","\n","                                     meta.votes_side  convo_id  \\\n","0  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...     13127   \n","1  {'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...     12997   \n","2  {'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...     13024   \n","3  {'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...     13015   \n","4  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...     13016   \n","\n","                                     case_transcript  \n","0  Number 71, Lonnie Affronti versus United State...  \n","1  Number 410, American Airlines, Incorporated ve...  \n","2  Number 410, American Airlines, Incorporated ve...  \n","3  Number 351, R.V. Archawski et al. versus Basil...  \n","4  Number 38, Raymond C. Armstrong versus Mary R....  "],"text/html":["\n","  <div id=\"df-ae39e30c-db61-4637-9b91-ce76e37e3e58\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>vectors</th>\n","      <th>meta.case_id</th>\n","      <th>meta.advocates</th>\n","      <th>meta.win_side</th>\n","      <th>meta.votes_side</th>\n","      <th>convo_id</th>\n","      <th>case_transcript</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[]</td>\n","      <td>1955_71</td>\n","      <td>{'harry_f_murphy': {'side': 1, 'role': 'inferr...</td>\n","      <td>0.0</td>\n","      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n","      <td>13127</td>\n","      <td>Number 71, Lonnie Affronti versus United State...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>[]</td>\n","      <td>1955_410</td>\n","      <td>{'howard_c_westwood': {'side': 1, 'role': 'inf...</td>\n","      <td>1.0</td>\n","      <td>{'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...</td>\n","      <td>12997</td>\n","      <td>Number 410, American Airlines, Incorporated ve...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>[]</td>\n","      <td>1955_410</td>\n","      <td>{'howard_c_westwood': {'side': 1, 'role': 'inf...</td>\n","      <td>1.0</td>\n","      <td>{'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...</td>\n","      <td>13024</td>\n","      <td>Number 410, American Airlines, Incorporated ve...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>[]</td>\n","      <td>1955_351</td>\n","      <td>{'harry_d_graham': {'side': 3, 'role': 'inferr...</td>\n","      <td>1.0</td>\n","      <td>{'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...</td>\n","      <td>13015</td>\n","      <td>Number 351, R.V. Archawski et al. versus Basil...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>[]</td>\n","      <td>1955_38</td>\n","      <td>{'robert_n_gorman': {'side': 3, 'role': 'infer...</td>\n","      <td>0.0</td>\n","      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n","      <td>13016</td>\n","      <td>Number 38, Raymond C. Armstrong versus Mary R....</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae39e30c-db61-4637-9b91-ce76e37e3e58')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ae39e30c-db61-4637-9b91-ce76e37e3e58 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ae39e30c-db61-4637-9b91-ce76e37e3e58');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}],"source":["# df_test = add_transcripts(df_test)\n","df_args.head()"],"id":"f81S4FOJOe8h"},{"cell_type":"code","source":["df_args = df_args.rename(columns={'meta.case_id': 'case_id', 'case_transcript': 'words'})\n","df_test = df_test.merge(df_args[['convo_id', 'words']], on='convo_id')\n"],"metadata":{"id":"YsmdjkDQ92xL","executionInfo":{"status":"ok","timestamp":1683153595464,"user_tz":420,"elapsed":843,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"}}},"id":"YsmdjkDQ92xL","execution_count":24,"outputs":[]},{"cell_type":"code","source":["df_test.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"E9bNxdCwA_pn","executionInfo":{"status":"ok","timestamp":1683153680042,"user_tz":420,"elapsed":266,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"}},"outputId":"473b7819-e84a-471b-c0b5-c1aedcfa7235"},"id":"E9bNxdCwA_pn","execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        case_id  win_side  convo_id  term docket_id mq_score  \\\n","0       1960_42       1.0     14077  1960        42    0.443   \n","1  2008_07-1209       1.0     23187  2008   07-1209    0.576   \n","2      1967_363       1.0     14890  1967       363   -1.043   \n","3   1976_76-128       1.0     16443  1976    76-128    0.473   \n","4  2014_13-6827       1.0     23221  2014   13-6827   -0.227   \n","\n","                                               words  \n","0  Number 42, Small Business Administration, Peti...  \n","1  We will hear argument first this morning in Ca...  \n","2  Number 363, United States et al.Petitioner, ve...  \n","3  We will hear arguments next in 76-128, Mandel,...  \n","4  We'll hear argument first this morning in Case...  "],"text/html":["\n","  <div id=\"df-a32eb19c-5c65-4f62-8da1-4c61511e9578\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>case_id</th>\n","      <th>win_side</th>\n","      <th>convo_id</th>\n","      <th>term</th>\n","      <th>docket_id</th>\n","      <th>mq_score</th>\n","      <th>words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1960_42</td>\n","      <td>1.0</td>\n","      <td>14077</td>\n","      <td>1960</td>\n","      <td>42</td>\n","      <td>0.443</td>\n","      <td>Number 42, Small Business Administration, Peti...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2008_07-1209</td>\n","      <td>1.0</td>\n","      <td>23187</td>\n","      <td>2008</td>\n","      <td>07-1209</td>\n","      <td>0.576</td>\n","      <td>We will hear argument first this morning in Ca...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1967_363</td>\n","      <td>1.0</td>\n","      <td>14890</td>\n","      <td>1967</td>\n","      <td>363</td>\n","      <td>-1.043</td>\n","      <td>Number 363, United States et al.Petitioner, ve...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1976_76-128</td>\n","      <td>1.0</td>\n","      <td>16443</td>\n","      <td>1976</td>\n","      <td>76-128</td>\n","      <td>0.473</td>\n","      <td>We will hear arguments next in 76-128, Mandel,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2014_13-6827</td>\n","      <td>1.0</td>\n","      <td>23221</td>\n","      <td>2014</td>\n","      <td>13-6827</td>\n","      <td>-0.227</td>\n","      <td>We'll hear argument first this morning in Case...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a32eb19c-5c65-4f62-8da1-4c61511e9578')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a32eb19c-5c65-4f62-8da1-4c61511e9578 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a32eb19c-5c65-4f62-8da1-4c61511e9578');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":25}]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":884,"status":"ok","timestamp":1683153682101,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"onpQaxOCrV1t"},"outputs":[],"source":["# df_test.to_csv('/content/drive/MyDrive/INFO251Final/TestConvoTranscripts.csv')"],"id":"onpQaxOCrV1t"},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683153682402,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"35ed08d4"},"outputs":[],"source":["# convert to int for later reference by language models \n","df_test['win_side'] = df_test['win_side'].astype(int)"],"id":"35ed08d4"},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683153682403,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"rjiXn8IfO1I1","outputId":"2176ee04-de29-4439-9728-9a642dde2c15"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        case_id  win_side  convo_id  term docket_id mq_score  \\\n","0       1960_42         1     14077  1960        42    0.443   \n","1  2008_07-1209         1     23187  2008   07-1209    0.576   \n","2      1967_363         1     14890  1967       363   -1.043   \n","3   1976_76-128         1     16443  1976    76-128    0.473   \n","4  2014_13-6827         1     23221  2014   13-6827   -0.227   \n","\n","                                               words  \n","0  Number 42, Small Business Administration, Peti...  \n","1  We will hear argument first this morning in Ca...  \n","2  Number 363, United States et al.Petitioner, ve...  \n","3  We will hear arguments next in 76-128, Mandel,...  \n","4  We'll hear argument first this morning in Case...  "],"text/html":["\n","  <div id=\"df-d1280c43-4658-4ee5-ae5a-6982b09ed96d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>case_id</th>\n","      <th>win_side</th>\n","      <th>convo_id</th>\n","      <th>term</th>\n","      <th>docket_id</th>\n","      <th>mq_score</th>\n","      <th>words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1960_42</td>\n","      <td>1</td>\n","      <td>14077</td>\n","      <td>1960</td>\n","      <td>42</td>\n","      <td>0.443</td>\n","      <td>Number 42, Small Business Administration, Peti...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2008_07-1209</td>\n","      <td>1</td>\n","      <td>23187</td>\n","      <td>2008</td>\n","      <td>07-1209</td>\n","      <td>0.576</td>\n","      <td>We will hear argument first this morning in Ca...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1967_363</td>\n","      <td>1</td>\n","      <td>14890</td>\n","      <td>1967</td>\n","      <td>363</td>\n","      <td>-1.043</td>\n","      <td>Number 363, United States et al.Petitioner, ve...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1976_76-128</td>\n","      <td>1</td>\n","      <td>16443</td>\n","      <td>1976</td>\n","      <td>76-128</td>\n","      <td>0.473</td>\n","      <td>We will hear arguments next in 76-128, Mandel,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2014_13-6827</td>\n","      <td>1</td>\n","      <td>23221</td>\n","      <td>2014</td>\n","      <td>13-6827</td>\n","      <td>-0.227</td>\n","      <td>We'll hear argument first this morning in Case...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1280c43-4658-4ee5-ae5a-6982b09ed96d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d1280c43-4658-4ee5-ae5a-6982b09ed96d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d1280c43-4658-4ee5-ae5a-6982b09ed96d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}],"source":["df_test.head()"],"id":"rjiXn8IfO1I1"},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683153682961,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"_PrUeVn3e2i_","outputId":"5497feab-617d-40db-b6df-0bbede8b3516"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["84"]},"metadata":{},"execution_count":29}],"source":["import gc\n","gc.collect()"],"id":"_PrUeVn3e2i_"},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1683153682961,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"o8kgeqbghqPn"},"outputs":[],"source":["#### ONLY FOR UTTERANCES\n","# Run train test split with conversation grouping \n","\n","if utts:\n","  gss = GroupShuffleSplit(n_splits=1, train_size=0.7, random_state=123)"],"id":"o8kgeqbghqPn"},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1683153684656,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"5CN_oX51h0u3"},"outputs":[],"source":["# create train and temp split. Temp split will be split in half into testing and validation sets\n","# for train_idx, test_idx in gss.split(df_test, groups=df_test['convo_id']):\n","#     train_df = df_test.iloc[train_idx]\n","#     temp_df = df_test.iloc[test_idx]"],"id":"5CN_oX51h0u3"},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683153686469,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"A12hUMpc_C7n"},"outputs":[],"source":["# split dataset into train, validation and test sets\n","train_text, temp_text, train_labels, temp_labels = train_test_split(df_test['words'], \n","                                                                    df_test['win_side'], \n","                                                                    random_state=123, \n","                                                                    test_size=0.3)\n","\n","\n","val_text, test_text, val_labels, test_labels = train_test_split(temp_text, \n","                                                                temp_labels, \n","                                                                random_state=123, \n","                                                                test_size=0.5)"],"id":"A12hUMpc_C7n"},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":233,"status":"ok","timestamp":1683153692901,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"r4HG8ek-zOh2","outputId":"885a23d4-9b65-4ab5-e3f7-16b9daaa8926"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2977    1\n","1139    1\n","5666    1\n","5824    1\n","4467    0\n","       ..\n","5218    1\n","4060    1\n","1346    0\n","3454    0\n","3582    1\n","Name: win_side, Length: 4900, dtype: int64"]},"metadata":{},"execution_count":33}],"source":["train_labels"],"id":"r4HG8ek-zOh2"},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683153693416,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"GC5sdK_nkpKy","outputId":"708e6d6f-bd67-4a37-a5da-f0247cb0191c"},"outputs":[{"output_type":"stream","name":"stdout","text":["AutoModel\t AutoModelForSequenceClassification\t AutoTokenizer\t BertTokenizerFast\t BigBirdModel\t BigBirdTokenizerFast\t DataLoader\t GradScaler\t GroupShuffleSplit\t \n","RandomSampler\t SequentialSampler\t TensorDataset\t add_transcripts\t autocast\t classification_report\t clean_convos\t clean_utts\t compute_class_weight\t \n","device\t df_args\t df_convo\t df_test\t drive\t gc\t get_random_chunk\t martin_quinn\t nn\t \n","np\t os\t path\t pd\t random\t temp_labels\t temp_text\t test_labels\t test_text\t \n","torch\t train_labels\t train_test_split\t train_text\t transformers\t utts\t val_labels\t val_text\t \n"]}],"source":["%who"],"id":"GC5sdK_nkpKy"},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1683153693416,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"qXT5hgy2kHpR"},"outputs":[],"source":["# delete older dfs to free up memory \n","del(martin_quinn)"],"id":"qXT5hgy2kHpR"},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683153694164,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"ibtNv7PKk1gO","outputId":"42c07f08-81a7-4125-a56d-f98f7ffbae00"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":36}],"source":["gc.collect()"],"id":"ibtNv7PKk1gO"},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3745,"status":"ok","timestamp":1683153697906,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"89adcb50","outputId":"799a7b9e-f80c-41b2-ec8e-d4cc6a2a3668"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["########################\n","# BigBird Model\n","# Load the BigBird model\n","# bigbird = BigBirdModel.from_pretrained('google/bigbird-roberta-base')\n","\n","# Load the BigBird tokenizer\n","# tokenizer = BigBirdTokenizerFast.from_pretrained('google/bigbird-roberta-base')\n","#########################\n","\n","\n","#########################\n","# BERT base model\n","# import BERT-base pretrained model\n","#bert = AutoModel.from_pretrained('bert-base-uncased')\n","\n","# Load the BERT tokenizer\n","#tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","#########################\n","\n","\n","#########################\n","# DeBERTa v3 base model\n","Deberta = AutoModelForSequenceClassification.from_pretrained('microsoft/deberta-v3-base', num_labels=2)\n","\n","# Load the DeBERTa v3 tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base', model_max_length=512)\n","\n","# deberta changes some stuff, set flag to trigger\n","model_name = 'deberta'\n","#########################"],"id":"89adcb50"},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"executionInfo":{"elapsed":2513,"status":"ok","timestamp":1683153700416,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"c7f52918","outputId":"8332f4f2-ce48-4821-cb8a-60ab0a17257f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Axes: >"]},"metadata":{},"execution_count":38},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# get length of all the messages in the train set\n","seq_len = [len(i.split()) for i in train_text]\n","\n","pd.Series(seq_len).hist()"],"id":"c7f52918"},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1683153700417,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"_hWgefXWNBaO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fa441a2c-cc6a-4ee7-aced-f5e8ac44ac9b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2977    1\n","1139    1\n","5666    1\n","5824    1\n","4467    0\n","       ..\n","5218    1\n","4060    1\n","1346    0\n","3454    0\n","3582    1\n","Name: win_side, Length: 4900, dtype: int64"]},"metadata":{},"execution_count":39}],"source":["train_labels"],"id":"_hWgefXWNBaO"},{"cell_type":"markdown","metadata":{"id":"58KisfDzNJw0"},"source":["The below cells exceed Google's RAM limits. The code above attempts to split tokenization up"],"id":"58KisfDzNJw0"},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":119678,"status":"ok","timestamp":1683153820087,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"hQJN2Ej5M9aP","outputId":"d878e6f9-cf34-4876-e58b-79b0b5156104"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}],"source":["# tokenize and encode sequences in the training set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    pad_to_max_length=True,\n","    truncation=True\n",")\n"],"id":"hQJN2Ej5M9aP"},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":25010,"status":"ok","timestamp":1683153845086,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"VlHBgbSgM_W3"},"outputs":[],"source":["# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    pad_to_max_length=True,\n","    truncation=True\n",")"],"id":"VlHBgbSgM_W3"},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":24593,"status":"ok","timestamp":1683153869663,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"be0c5e89"},"outputs":[],"source":["# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    pad_to_max_length=True,\n","    truncation=True\n",")"],"id":"be0c5e89"},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":368,"status":"ok","timestamp":1683153870429,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"ad7b5fe7"},"outputs":[],"source":["## convert lists to tensors\n","\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"],"id":"ad7b5fe7"},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1683153871446,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"zKyHSA0h--ml","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ea89abdf-5f7f-4eef-eff6-86a58971b27c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":44}],"source":["gc.collect()"],"id":"zKyHSA0h--ml"},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1683153871447,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"8825f286"},"outputs":[],"source":["##### setting hyper parameters \n","\n","#define a batch size\n","batch_size = 64\n","\n","# define accumulation steps for use in gradient accumulation \n","accumulation_steps = 4\n","\n","# define learning rate for optimizer\n","learning_rate = 2e-5\n","\n","# define regularization for optimizer\n","weight_decay=1e-4\n","\n","# define Dropout Rate\n","dropout=0.5\n","\n","# define epochs\n","epochs = 5"],"id":"8825f286"},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1683153871448,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"TdDtfW_d2sHY","outputId":"f7381aa2-76d7-4e7f-f3d7-2b1c154f69f8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 1, 1,  ..., 0, 0, 1])"]},"metadata":{},"execution_count":46}],"source":["train_y"],"id":"TdDtfW_d2sHY"},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1683153871448,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"x2koBDFFxxij"},"outputs":[],"source":["# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"],"id":"x2koBDFFxxij"},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683153871448,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"d91a93e5"},"outputs":[],"source":["# freeze all the parameters\n","\n","#original\n","#for param in bigbird.parameters():\n","   # param.requires_grad = False\n","#myswitch\n","for param in Deberta.parameters():\n","    param.requires_grad = False"],"id":"d91a93e5"},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683153871449,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"6af2e1d7"},"outputs":[],"source":["class BERT_Arch(nn.Module):\n","\n","    def __init__(self, Deberta):\n","        super(BERT_Arch, self).__init__()\n","\n","        self.deberta = Deberta\n","\n","        # dropout layer\n","        self.dropout = nn.Dropout(dropout)\n","\n","        # relu activation function\n","        self.relu = nn.ReLU()\n","\n","        # dense layer 1\n","        self.fc1 = nn.Linear(768, 512)\n","\n","        # dense layer 2 (Output layer)\n","        self.fc2 = nn.Linear(512, 1)\n","\n","    # define the forward pass\n","    def forward(self, sent_id, mask):\n","\n","        # pass the inputs to the model\n","        if model_name == 'deberta':\n","            outputs = self.deberta(sent_id, attention_mask=mask, return_dict=True, output_hidden_states=True)\n","            cls_hs = outputs['hidden_states'][-1][:, 0]\n","        else:\n","            _, cls_hs = self.model(sent_id, attention_mask=mask, return_dict=False)\n","\n","        x = self.fc1(cls_hs)\n","\n","        x = self.relu(x)\n","\n","        x = self.dropout(x)\n","\n","        # output layer\n","        x = self.fc2(x)\n","\n","        return x\n"],"id":"6af2e1d7"},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":4925,"status":"ok","timestamp":1683153876366,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"9909837a"},"outputs":[],"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(Deberta)\n","\n","# push the model to GPU\n","model = model.to(device)"],"id":"9909837a"},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5214,"status":"ok","timestamp":1683153881570,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"952fba40","outputId":"39815d39-7969-4d38-c28d-c9e02af09c1f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = AdamW(model.parameters(),lr = learning_rate, weight_decay=weight_decay) "],"id":"952fba40"},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683153881571,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"KbXrYP__MOhT"},"outputs":[],"source":["# Only use if NVIDIA Apex interface installed \n","\n","\n","\n","\n","\n","# initialize mixed-precision training after defining model and optimizer\n","# model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")"],"id":"KbXrYP__MOhT"},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2469,"status":"ok","timestamp":1683153884037,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"3df15cfd","outputId":"11d31e3c-c9c0-47ac-8991-33e6229897d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Class Weights: [1.31791286 0.80565603]\n"]}],"source":["# # compute the class weights\n","class_weights = compute_class_weight('balanced', \n","                                     classes=np.unique(train_labels), \n","                                     y=train_labels)\n","\n","print(\"Class Weights:\",class_weights)\n","\n","\n","weights_per_class = torch.tensor(class_weights, device=device)\n","weights = torch.zeros((batch_size, 1))\n","\n","for idx, weight in enumerate(weights_per_class):\n","    weights[:, 0] = weight\n","\n","# push to GPU\n","weights = weights.to(device)"],"id":"3df15cfd"},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1683153884038,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"7f26c12e"},"outputs":[],"source":["# converting list of class weights to a tensor\n","weights= torch.tensor(class_weights,dtype=torch.float)\n","\n","# push to GPU\n","weights = weights.to(device)\n","\n","# define the loss function\n","cross_entropy = nn.BCEWithLogitsLoss()"],"id":"7f26c12e"},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1683153884039,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"e8af0312"},"outputs":[],"source":["# Instantiate GradScaler outside the train() function\n","scaler = GradScaler()\n","\n","# function to train the model\n","def train():\n","    \n","    model.train()\n","    total_loss, total_accuracy = 0, 0\n","    \n","    # empty list to save model predictions\n","    total_preds=[]\n","    \n","    # iterate over batches\n","    for step, batch in enumerate(train_dataloader):\n","        \n","        # progress update after every 50 batches.\n","        if step % 50 == 0 and not step == 0:\n","            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","        \n","        # push the batch to gpu\n","        batch = [r.to(device) for r in batch]\n","        \n","        sent_id, mask, labels = batch\n","\n","        # Calculate the batch_weights using the labels of the current batch\n","        batch_labels = labels.to(device)\n","        batch_weights = torch.tensor([class_weights[label.item()] for label in batch_labels]).to(device)\n","        # batch_weights = weights_per_class[labels.to(device)]\n","        \n","        # clear previously calculated gradients \n","        model.zero_grad()        \n","\n","        # Use autocast for mixed-precision training\n","        with autocast():\n","            preds = model(sent_id, mask)\n","            loss = cross_entropy(preds, batch_labels.unsqueeze(1).float())\n","\n","        # Scale the loss and perform backward pass\n","        loss = (loss * batch_weights).mean()\n","        scaler.scale(loss).backward()\n","\n","        # Gradient accumulation\n","        if (step + 1) % accumulation_steps == 0:\n","            # Clip gradients and update optimizer\n","            scaler.unscale_(optimizer)\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            scaler.step(optimizer)\n","            scaler.update()\n","            model.zero_grad()\n","\n","        # model predictions are stored on GPU. So, push it to CPU\n","        preds=preds.detach().cpu().numpy()\n","\n","        # append the model predictions\n","        total_preds.append(preds)\n","\n","    # compute the training loss of the epoch\n","    avg_loss = total_loss / len(train_dataloader)\n","    \n","    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","      # reshape the predictions in form of (number of samples, no. of classes)\n","    total_preds  = np.concatenate(total_preds, axis=0)\n","\n","    #returns the loss and predictions\n","    return avg_loss, total_preds\n"],"id":"e8af0312"},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683153884039,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"14ca26a9"},"outputs":[],"source":["# function for evaluating the model\n","def evaluate():\n","    \n","    print(\"\\nEvaluating...\")\n","    \n","    # deactivate dropout layers\n","    model.eval()\n","\n","    total_loss, total_accuracy = 0, 0\n","    \n","    # empty list to save the model predictions\n","    total_preds = []\n","\n","    # iterate over batches\n","    for step,batch in enumerate(val_dataloader):\n","        \n","        # Progress update every 50 batches.\n","        if step % 50 == 0 and not step == 0:\n","            \n","            # Calculate elapsed time in minutes.\n","            #Issue here so I commented out\n","            #elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","        # push the batch to gpu\n","        batch = [t.to(device) for t in batch]\n","\n","        sent_id, mask, labels = batch\n","\n","        # Calculate the batch_weights using the labels of the current batch\n","        batch_labels = labels.to(device)\n","        batch_weights = torch.tensor([class_weights[label.item()] for label in batch_labels]).to(device)\n","\n","        # deactivate autograd\n","        with torch.no_grad():\n","            \n","            # model predictions\n","            preds = model(sent_id, mask)\n","\n","            # compute the validation loss between actual and predicted values\n","            loss = cross_entropy(preds, batch_labels.unsqueeze(1).float())\n","            # Scale the loss by the batch_weights\n","            loss = (loss * batch_weights).mean()\n","\n","            total_loss = total_loss + loss.item()\n","\n","            preds = preds.detach().cpu().numpy()\n","\n","            total_preds.append(preds)\n","\n","    # compute the validation loss of the epoch\n","    avg_loss = total_loss / len(val_dataloader) \n","\n","    # reshape the predictions in form of (number of samples, no. of classes)\n","    total_preds  = np.concatenate(total_preds, axis=0)\n","\n","    return avg_loss, total_preds"],"id":"14ca26a9"},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1683153884371,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"9504517a","outputId":"bcd7b99d-e7fc-402a-bf36-e42f15bc249e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["87"]},"metadata":{},"execution_count":57}],"source":["# import gc\n","gc.collect()"],"id":"9504517a"},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":190435,"status":"ok","timestamp":1683154074792,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"160739aa","outputId":"e4387e30-cd25-4411-bbed-b7660b2e490d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Epoch 1 / 5\n","  Batch    50  of     77.\n","\n","Evaluating...\n","\n","Training Loss: 0.000\n","Validation Loss: 0.648\n","\n"," Epoch 2 / 5\n","  Batch    50  of     77.\n","\n","Evaluating...\n","\n","Training Loss: 0.000\n","Validation Loss: 0.634\n","\n"," Epoch 3 / 5\n","  Batch    50  of     77.\n","\n","Evaluating...\n","\n","Training Loss: 0.000\n","Validation Loss: 0.629\n","\n"," Epoch 4 / 5\n","  Batch    50  of     77.\n","\n","Evaluating...\n","\n","Training Loss: 0.000\n","Validation Loss: 0.625\n","\n"," Epoch 5 / 5\n","  Batch    50  of     77.\n","\n","Evaluating...\n","\n","Training Loss: 0.000\n","Validation Loss: 0.625\n"]}],"source":["##############################\n","#\n","#    RUN THE MODEL\n","#\n","##############################\n","\n","# set initial loss to infinite\n","best_valid_loss = float('16')\n","\n","# empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","#for each epoch\n","for epoch in range(epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss, _ = train()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'saved_weights.pt')\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    \n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"],"id":"160739aa"},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":501,"status":"ok","timestamp":1683154075273,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"ac748690","outputId":"c1d49f18-b226-42d2-a70d-a2d6da76cf47"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":59}],"source":["# #load weights of best model\n","# path = 'saved_weights.pt'\n","# # Move the model to CPU? \n","# model = model.to(device)\n","\n","# # Load weights and make predictions\n","# model.load_state_dict(torch.load(path, map_location=torch.device(device)))\n","\n","\n","#load weights of best model\n","path = 'saved_weights.pt'\n","model.load_state_dict(torch.load(path))"],"id":"ac748690"},{"cell_type":"code","execution_count":60,"metadata":{"executionInfo":{"elapsed":543,"status":"error","timestamp":1683154075808,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"6fd02379","colab":{"base_uri":"https://localhost:8080/","height":443},"outputId":"e07e9a50-2e8e-4412-c992-974e65708b51"},"outputs":[{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-3fbd384ee9eb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get predictions for test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-49-6507f476071e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'deberta'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeberta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden_states'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1309\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1311\u001b[0;31m         outputs = self.deberta(\n\u001b[0m\u001b[1;32m   1312\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1084\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 )\n\u001b[1;32m    520\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                 output_states = layer_module(\n\u001b[0m\u001b[1;32m    522\u001b[0m                     \u001b[0mnext_kv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     ):\n\u001b[0;32m--> 362\u001b[0;31m         attention_output = self.attention(\n\u001b[0m\u001b[1;32m    363\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     ):\n\u001b[0;32m--> 293\u001b[0;31m         self_output = self.self(\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mrel_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             rel_att = self.disentangled_attention_bias(\n\u001b[0m\u001b[1;32m    729\u001b[0m                 \u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mdisentangled_attention_bias\u001b[0;34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"c2p\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_att_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_key_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0mc2p_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_key_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mc2p_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelative_pos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0matt_span\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_span\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             c2p_att = torch.gather(\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 12.30 GiB (GPU 0; 39.56 GiB total capacity; 22.52 GiB already allocated; 5.49 GiB free; 32.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["# get predictions for test data\n","with torch.no_grad():\n","    preds = model(test_seq.to(device), test_mask.to(device))\n","    preds = preds.detach().cpu().numpy()\n","\n","# Move to CPU\n","# get predictions for test data\n","# with torch.no_grad():\n","#     preds = model(test_seq.to('cpu'), test_mask.to('cpu'))\n","#     preds = preds.detach().cpu().numpy()"],"id":"6fd02379"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1683154075809,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"B770iI6wqZ2o"},"outputs":[],"source":["gc.collect()"],"id":"B770iI6wqZ2o"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1683154076351,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"c9628385"},"outputs":[],"source":["# model's performance\n","preds = np.argmax(preds, axis = 1)\n","print(classification_report(test_y, preds))"],"id":"c9628385"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1683154076352,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"1d8bb1e8"},"outputs":[],"source":["preds"],"id":"1d8bb1e8"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1683154076352,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"44cde729"},"outputs":[],"source":["del(model)\n","torch.cuda.empty_cache()"],"id":"44cde729"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1683154076352,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"},"user_tz":420},"id":"Uhk8hGo8to3I"},"outputs":[],"source":["gc.collect()"],"id":"Uhk8hGo8to3I"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2YoLUUFcuVol","executionInfo":{"status":"aborted","timestamp":1683154076352,"user_tz":420,"elapsed":8,"user":{"displayName":"Quinn Wilson","userId":"05763889598564787658"}}},"outputs":[],"source":[],"id":"2YoLUUFcuVol"}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1yMcFuEK6RC_xEEuvsuQBHlC4PVhMILMJ","timestamp":1683079943223}]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}