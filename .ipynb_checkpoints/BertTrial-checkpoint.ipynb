{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f46b13a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.0-cp39-none-macosx_11_0_arm64.whl (55.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: networkx in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from torch) (2.8.6)\n",
      "Requirement already satisfied: jinja2 in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, filelock, torch\n",
      "Successfully installed filelock-3.12.0 mpmath-1.3.0 sympy-1.11.1 torch-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ac0a684e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.98-cp39-cp39-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.98\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "321d29cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from transformers) (3.12.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-macosx_12_0_arm64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from transformers) (1.23.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: fsspec in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2022.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/quinn/opt/anaconda3/envs/pp275/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "152682d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import transformers\n",
    "from transformers import BigBirdModel, BigBirdTokenizerFast\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "99ce5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c972caa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>vectors</th>\n",
       "      <th>case_id</th>\n",
       "      <th>advocates</th>\n",
       "      <th>win_side</th>\n",
       "      <th>votes_side</th>\n",
       "      <th>convo_id</th>\n",
       "      <th>term</th>\n",
       "      <th>docket_id</th>\n",
       "      <th>mq_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1955_71</td>\n",
       "      <td>{'harry_f_murphy': {'side': 1, 'role': 'inferr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>13127</td>\n",
       "      <td>1955</td>\n",
       "      <td>71</td>\n",
       "      <td>0.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>1955_410</td>\n",
       "      <td>{'howard_c_westwood': {'side': 1, 'role': 'inf...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...</td>\n",
       "      <td>12997</td>\n",
       "      <td>1955</td>\n",
       "      <td>410</td>\n",
       "      <td>0.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>1955_410</td>\n",
       "      <td>{'howard_c_westwood': {'side': 1, 'role': 'inf...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...</td>\n",
       "      <td>13024</td>\n",
       "      <td>1955</td>\n",
       "      <td>410</td>\n",
       "      <td>0.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>1955_351</td>\n",
       "      <td>{'harry_d_graham': {'side': 3, 'role': 'inferr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...</td>\n",
       "      <td>13015</td>\n",
       "      <td>1955</td>\n",
       "      <td>351</td>\n",
       "      <td>0.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>1955_38</td>\n",
       "      <td>{'robert_n_gorman': {'side': 3, 'role': 'infer...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>13016</td>\n",
       "      <td>1955</td>\n",
       "      <td>38</td>\n",
       "      <td>0.559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 vectors   case_id  \\\n",
       "0           0      []   1955_71   \n",
       "1           1      []  1955_410   \n",
       "2           2      []  1955_410   \n",
       "3           3      []  1955_351   \n",
       "4           4      []   1955_38   \n",
       "\n",
       "                                           advocates  win_side  \\\n",
       "0  {'harry_f_murphy': {'side': 1, 'role': 'inferr...       0.0   \n",
       "1  {'howard_c_westwood': {'side': 1, 'role': 'inf...       1.0   \n",
       "2  {'howard_c_westwood': {'side': 1, 'role': 'inf...       1.0   \n",
       "3  {'harry_d_graham': {'side': 3, 'role': 'inferr...       1.0   \n",
       "4  {'robert_n_gorman': {'side': 3, 'role': 'infer...       0.0   \n",
       "\n",
       "                                          votes_side  convo_id  term  \\\n",
       "0  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...     13127  1955   \n",
       "1  {'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...     12997  1955   \n",
       "2  {'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...     13024  1955   \n",
       "3  {'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...     13015  1955   \n",
       "4  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 0,...     13016  1955   \n",
       "\n",
       "  docket_id mq_score  \n",
       "0        71    0.559  \n",
       "1       410    0.559  \n",
       "2       410    0.559  \n",
       "3       351    0.559  \n",
       "4        38    0.559  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Outcomes_NoTranscript.csv\")\n",
    "df.drop(df[df['win_side'] == -1.0].index, inplace = True)\n",
    "df.drop(df[df['win_side'] == 2.0].index, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "38d10743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    4930\n",
       "0.0    2868\n",
       "Name: win_side, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['win_side'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9fbecbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.sample(n=100, replace=False, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c069d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "de075620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['words'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4d267fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_test.iterrows(): \n",
    "    folder_path = '/Users/quinn/Documents/GradSchool/Spring2023/INFO251/Trancripts_Case_Convo/'\n",
    "    read_path = folder_path+str(row['convo_id'])+'_'+str(row['case_id'])+'.txt'\n",
    "    transcript = open(read_path, 'r')\n",
    "    text = transcript.read()\n",
    "#     print(transcript)\n",
    "    df_test.at[index, 'words'] = text\n",
    "    transcript.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "810233fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(columns=['vectors', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5dc56282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case_id       False\n",
       "advocates     False\n",
       "win_side      False\n",
       "votes_side    False\n",
       "convo_id      False\n",
       "term          False\n",
       "docket_id     False\n",
       "mq_score      False\n",
       "words         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "35ed08d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>advocates</th>\n",
       "      <th>win_side</th>\n",
       "      <th>votes_side</th>\n",
       "      <th>convo_id</th>\n",
       "      <th>term</th>\n",
       "      <th>docket_id</th>\n",
       "      <th>mq_score</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3368</th>\n",
       "      <td>1975_75-436</td>\n",
       "      <td>{'brice_m_clagett': {'side': 1, 'role': 'Argue...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'j__potter_stewart': 1, 'j__thurgood_marshall...</td>\n",
       "      <td>15820</td>\n",
       "      <td>1975</td>\n",
       "      <td>75-436</td>\n",
       "      <td>0.492</td>\n",
       "      <td>Mr. Cox.Mr. Chief Justice and may it please th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>1966_206</td>\n",
       "      <td>{'w_d_deakins_jr': {'side': 3, 'role': 'inferr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'j__john_m_harlan2': 0, 'j__hugo_l_black': 1,...</td>\n",
       "      <td>15469</td>\n",
       "      <td>1966</td>\n",
       "      <td>206</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>Let's get to the cases.\\nNumber 206, Houston I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>1965_8</td>\n",
       "      <td>{'donald_f_turner': {'side': 1, 'role': 'for t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'j__earl_warren': -1, 'j__hugo_l_black': -1, ...</td>\n",
       "      <td>14885</td>\n",
       "      <td>1965</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>Number 8, United States, appellant, versus Huc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7069</th>\n",
       "      <td>2009_132-orig</td>\n",
       "      <td>{'edwin_s_kneedler': {'side': 2, 'role': 'Depu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'j__john_g_roberts_jr': 1, 'j__john_paul_stev...</td>\n",
       "      <td>21669</td>\n",
       "      <td>2009</td>\n",
       "      <td>132-orig</td>\n",
       "      <td>0.516</td>\n",
       "      <td>We will hear argument first this morning in Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5637</th>\n",
       "      <td>1991_90-5844</td>\n",
       "      <td>{'pamela_s_moran': {'side': 0, 'role': 'on beh...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'j__byron_r_white': 1, 'j__harry_a_blackmun':...</td>\n",
       "      <td>19845</td>\n",
       "      <td>1991</td>\n",
       "      <td>90-5844</td>\n",
       "      <td>0.756</td>\n",
       "      <td>We'll hear argument now on No. 90-5844, Terry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>1959_58</td>\n",
       "      <td>{'charles_wolfe_kalp': {'side': 1, 'role': 'in...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...</td>\n",
       "      <td>13914</td>\n",
       "      <td>1959</td>\n",
       "      <td>58</td>\n",
       "      <td>0.335</td>\n",
       "      <td>Number 58, Albert H. Grisham, Petitioner, vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7645</th>\n",
       "      <td>2017_16-1150</td>\n",
       "      <td>{'andrew_c_simpson': {'side': 1, 'role': 'for ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'j__john_g_roberts_jr': 1, 'j__anthony_m_kenn...</td>\n",
       "      <td>24591</td>\n",
       "      <td>2017</td>\n",
       "      <td>16-1150</td>\n",
       "      <td>0.298</td>\n",
       "      <td>We'll hear argument first this morning in Case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>1976_75-699</td>\n",
       "      <td>{'keith_a_jones': {'side': 1, 'role': 'Deputy ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'j__potter_stewart': 1, 'j__thurgood_marshall...</td>\n",
       "      <td>17601</td>\n",
       "      <td>1976</td>\n",
       "      <td>75-699</td>\n",
       "      <td>0.473</td>\n",
       "      <td>We will hear argument next in 75-699 Mathews a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>1962_21</td>\n",
       "      <td>{'eli_freed': {'side': 0, 'role': 'argued and ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'j__john_m_harlan2': 1, 'j__hugo_l_black': 0,...</td>\n",
       "      <td>14497</td>\n",
       "      <td>1962</td>\n",
       "      <td>21</td>\n",
       "      <td>-1.079</td>\n",
       "      <td>Number 255, United States, Petitioner, versus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>1989_89-504</td>\n",
       "      <td>{'david_l_shapiro': {'side': 1, 'role': 'on be...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'j__thurgood_marshall': 1, 'j__william_j_bren...</td>\n",
       "      <td>18810</td>\n",
       "      <td>1989</td>\n",
       "      <td>89-504</td>\n",
       "      <td>0.876</td>\n",
       "      <td>We'll hear argument now in Number 89-504, Loui...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            case_id                                          advocates  \\\n",
       "3368    1975_75-436  {'brice_m_clagett': {'side': 1, 'role': 'Argue...   \n",
       "2026       1966_206  {'w_d_deakins_jr': {'side': 3, 'role': 'inferr...   \n",
       "1955         1965_8  {'donald_f_turner': {'side': 1, 'role': 'for t...   \n",
       "7069  2009_132-orig  {'edwin_s_kneedler': {'side': 2, 'role': 'Depu...   \n",
       "5637   1991_90-5844  {'pamela_s_moran': {'side': 0, 'role': 'on beh...   \n",
       "...             ...                                                ...   \n",
       "810         1959_58  {'charles_wolfe_kalp': {'side': 1, 'role': 'in...   \n",
       "7645   2017_16-1150  {'andrew_c_simpson': {'side': 1, 'role': 'for ...   \n",
       "3523    1976_75-699  {'keith_a_jones': {'side': 1, 'role': 'Deputy ...   \n",
       "1490        1962_21  {'eli_freed': {'side': 0, 'role': 'argued and ...   \n",
       "5465    1989_89-504  {'david_l_shapiro': {'side': 1, 'role': 'on be...   \n",
       "\n",
       "      win_side                                         votes_side  convo_id  \\\n",
       "3368       1.0  {'j__potter_stewart': 1, 'j__thurgood_marshall...     15820   \n",
       "2026       0.0  {'j__john_m_harlan2': 0, 'j__hugo_l_black': 1,...     15469   \n",
       "1955       0.0  {'j__earl_warren': -1, 'j__hugo_l_black': -1, ...     14885   \n",
       "7069       0.0  {'j__john_g_roberts_jr': 1, 'j__john_paul_stev...     21669   \n",
       "5637       1.0  {'j__byron_r_white': 1, 'j__harry_a_blackmun':...     19845   \n",
       "...        ...                                                ...       ...   \n",
       "810        1.0  {'j__john_m_harlan2': 1, 'j__hugo_l_black': 1,...     13914   \n",
       "7645       1.0  {'j__john_g_roberts_jr': 1, 'j__anthony_m_kenn...     24591   \n",
       "3523       0.0  {'j__potter_stewart': 1, 'j__thurgood_marshall...     17601   \n",
       "1490       1.0  {'j__john_m_harlan2': 1, 'j__hugo_l_black': 0,...     14497   \n",
       "5465       1.0  {'j__thurgood_marshall': 1, 'j__william_j_bren...     18810   \n",
       "\n",
       "      term docket_id mq_score  \\\n",
       "3368  1975    75-436    0.492   \n",
       "2026  1966       206   -0.414   \n",
       "1955  1965         8    -0.56   \n",
       "7069  2009  132-orig    0.516   \n",
       "5637  1991   90-5844    0.756   \n",
       "...    ...       ...      ...   \n",
       "810   1959        58    0.335   \n",
       "7645  2017   16-1150    0.298   \n",
       "3523  1976    75-699    0.473   \n",
       "1490  1962        21   -1.079   \n",
       "5465  1989    89-504    0.876   \n",
       "\n",
       "                                                  words  \n",
       "3368  Mr. Cox.Mr. Chief Justice and may it please th...  \n",
       "2026  Let's get to the cases.\\nNumber 206, Houston I...  \n",
       "1955  Number 8, United States, appellant, versus Huc...  \n",
       "7069  We will hear argument first this morning in Ca...  \n",
       "5637  We'll hear argument now on No. 90-5844, Terry ...  \n",
       "...                                                 ...  \n",
       "810   Number 58, Albert H. Grisham, Petitioner, vers...  \n",
       "7645  We'll hear argument first this morning in Case...  \n",
       "3523  We will hear argument next in 75-699 Mathews a...  \n",
       "1490  Number 255, United States, Petitioner, versus ...  \n",
       "5465  We'll hear argument now in Number 89-504, Loui...  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d146003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train dataset into train, validation and test sets\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df_test['words'], \n",
    "                                                                    df_test['win_side'], \n",
    "                                                                    random_state=123, \n",
    "                                                                    test_size=0.3)\n",
    "\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, \n",
    "                                                                temp_labels, \n",
    "                                                                random_state=123, \n",
    "                                                                test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "89adcb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load the BigBird model\n",
    "bigbird = BigBirdModel.from_pretrained('google/bigbird-roberta-base')\n",
    "\n",
    "# Load the BigBird tokenizer\n",
    "tokenizer = BigBirdTokenizerFast.from_pretrained('google/bigbird-roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c7f52918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "be0c5e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quinn/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ad7b5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert lists to tensors\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8825f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d91a93e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bigbird.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6af2e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bigbird):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        self.bigbird = bigbird \n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "        \n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "        \n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bigbird(sent_id, attention_mask=mask, return_dict=False)\n",
    "        \n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9909837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bigbird)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "952fba40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quinn/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),lr = 1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3df15cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [1.66666667 0.71428571]\n"
     ]
    }
   ],
   "source": [
    "# compute the class weights\n",
    "class_weights = compute_class_weight('balanced', \n",
    "                                     classes=np.unique(train_labels), \n",
    "                                     y=train_labels)\n",
    "\n",
    "print(\"Class Weights:\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7f26c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# push to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e8af0312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "    \n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "    \n",
    "    # iterate over batches\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        # progress update after every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "        \n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        \n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    \n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "      # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "14ca26a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "    \n",
    "    print(\"\\nEvaluating...\")\n",
    "    \n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "        \n",
    "        # Progress update every 25 batches.\n",
    "        if step % 25 == 0 and not step == 0:\n",
    "            \n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9504517a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2676"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "160739aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 11.39 GB, other allocations: 6.61 GB, max allowed: 18.13 GB). Tried to allocate 1.05 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [182]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, epochs))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#train model\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m train_loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#evaluate model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m valid_loss, _ \u001b[38;5;241m=\u001b[39m evaluate()\n",
      "Input \u001b[0;32mIn [175]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()        \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# get model predictions for the current batch\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# compute the loss between actual and predicted values\u001b[39;00m\n\u001b[1;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m cross_entropy(preds, labels)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [170]\u001b[0m, in \u001b[0;36mBERT_Arch.forward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sent_id, mask):\n\u001b[1;32m     25\u001b[0m     \n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#pass the inputs to the model  \u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     _, cls_hs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbigbird\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(cls_hs)\n\u001b[1;32m     31\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/transformers/models/big_bird/modeling_big_bird.py:2138\u001b[0m, in \u001b[0;36mBigBirdModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2128\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   2130\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   2131\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2132\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2135\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   2136\u001b[0m )\n\u001b[0;32m-> 2138\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2139\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2145\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2146\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2147\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mband_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mband_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocked_encoder_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocked_encoder_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2156\u001b[0m pooler_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output[:, \u001b[38;5;241m0\u001b[39m, :])) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/transformers/models/big_bird/modeling_big_bird.py:1632\u001b[0m, in \u001b[0;36mBigBirdEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, band_mask, from_mask, to_mask, blocked_encoder_mask, return_dict)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m   1620\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1621\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1629\u001b[0m         blocked_encoder_mask,\n\u001b[1;32m   1630\u001b[0m     )\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1632\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mband_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblocked_encoder_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1646\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/transformers/models/big_bird/modeling_big_bird.py:1484\u001b[0m, in \u001b[0;36mBigBirdLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, band_mask, from_mask, to_mask, blocked_encoder_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m   1469\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1470\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1481\u001b[0m ):\n\u001b[1;32m   1482\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1484\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mband_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mband_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_blocked_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocked_encoder_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_blocked_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocked_encoder_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1498\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1500\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/transformers/models/big_bird/modeling_big_bird.py:1397\u001b[0m, in \u001b[0;36mBigBirdAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, band_mask, from_mask, to_mask, from_blocked_mask, to_blocked_mask)\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1396\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBigBird cannot be used as a decoder when config.attention_type != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_full\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1397\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mband_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_blocked_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_blocked_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1401\u001b[0m attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m   1402\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/transformers/models/big_bird/modeling_big_bird.py:470\u001b[0m, in \u001b[0;36mBigBirdBlockSparseAttention.forward\u001b[0;34m(self, hidden_states, band_mask, from_mask, to_mask, from_blocked_mask, to_blocked_mask, output_attentions)\u001b[0m\n\u001b[1;32m    467\u001b[0m key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(hidden_states))\n\u001b[1;32m    468\u001b[0m value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(hidden_states))\n\u001b[0;32m--> 470\u001b[0m context_layer, attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbigbird_block_sparse_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mband_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_blocked_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_blocked_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_attention_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_random_blocks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_head_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_block_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_block_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplan_from_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplan_num_rand_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(batch_size, from_seq_length, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    495\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (context_layer, attention_probs) \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m (context_layer,)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/transformers/models/big_bird/modeling_big_bird.py:704\u001b[0m, in \u001b[0;36mBigBirdBlockSparseAttention.bigbird_block_sparse_attention\u001b[0;34m(self, query_layer, key_layer, value_layer, band_mask, from_mask, to_mask, from_blocked_mask, to_blocked_mask, n_heads, n_rand_blocks, attention_head_size, from_block_size, to_block_size, batch_size, from_seq_len, to_seq_len, seed, plan_from_length, plan_num_rand_blocks, output_attentions)\u001b[0m\n\u001b[1;32m    700\u001b[0m middle_query_matrix \u001b[38;5;241m=\u001b[39m blocked_query_matrix[:, :, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# sliding attention scores for q[-2:2]\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, -1] x [b, n_heads, from_seq_len//from_block_size-4, 3*to_block_size, -1]\u001b[39;00m\n\u001b[0;32m--> 704\u001b[0m inner_band_product \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_bmm_nd_transpose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmiddle_query_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_blocked_key_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m#     ==> [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, 3*to_block_size]\u001b[39;00m\n\u001b[1;32m    706\u001b[0m inner_band_product \u001b[38;5;241m=\u001b[39m inner_band_product \u001b[38;5;241m*\u001b[39m rsqrt_d\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/transformers/models/big_bird/modeling_big_bird.py:510\u001b[0m, in \u001b[0;36mBigBirdBlockSparseAttention.torch_bmm_nd_transpose\u001b[0;34m(inp_1, inp_2, ndim)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"Fast nd matrix multiplication with transpose\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# faster replacement of torch.einsum (bhqd,bhkd->bhqk)\u001b[39;00m\n\u001b[0;32m--> 510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43minp_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minp_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minp_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(inp_1\u001b[38;5;241m.\u001b[39mshape[: ndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m (inp_1\u001b[38;5;241m.\u001b[39mshape[ndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m], inp_2\u001b[38;5;241m.\u001b[39mshape[ndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m]))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 11.39 GB, other allocations: 6.61 GB, max allowed: 18.13 GB). Tried to allocate 1.05 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ac748690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6fd02379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c9628385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       2.0\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quinn/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/quinn/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/quinn/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/quinn/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/quinn/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/quinn/opt/anaconda3/envs/PP275/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1d8bb1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cde729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pp275",
   "language": "python",
   "name": "pp275"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
