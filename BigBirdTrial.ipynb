{"cells":[{"cell_type":"code","source":[" \"\"\"\n"," NOTE: For TPU only\n"," Must go to Command Pallette (Cmd/Ctrl+Shift+P) and enter \"Use Fallback Runtime\" to enable running older python\n"," \"\"\"\n"," #! pip install cloud-tpu-client==0.10.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp39-cp39-linux_x86_64.whl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"YAfl1CXOOsgt","executionInfo":{"status":"ok","timestamp":1683148424004,"user_tz":420,"elapsed":9,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"f1edb41d-c6ca-40a1-920e-dad7343f40b9"},"id":"YAfl1CXOOsgt","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nNOTE: For TPU only\\nMust go to Command Pallette (Cmd/Ctrl+Shift+P) and enter \"Use Fallback Runtime\" to enable running older python\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"code","execution_count":null,"id":"ac0a684e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ac0a684e","executionInfo":{"status":"ok","timestamp":1683148447564,"user_tz":420,"elapsed":10595,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"cb9a7e2f-caf3-4dfd-8c23-c41fc96263fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}],"source":["!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"id":"321d29cd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"321d29cd","executionInfo":{"status":"ok","timestamp":1683148462862,"user_tz":420,"elapsed":15306,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"ac1ad7e6-e53c-45a6-a451-123b1bf6bc62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["# install tools for pulling Supreme Court Arguments transcripts \n","# !pip3 install convokit\n","# !python3 -m spacy download en_core_web_sm"],"metadata":{"id":"iEX-j92xv1s_"},"id":"iEX-j92xv1s_","execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import pandas as pd\n","\n","\n","# Rather than load Corpus, we load the transcripts csv separately \n","# from convokit import Corpus, download\n","# import nltk"],"metadata":{"id":"9ZgKS8RSv66V"},"id":"9ZgKS8RSv66V","execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CbKVAQgtnNKF","executionInfo":{"status":"ok","timestamp":1683148495049,"user_tz":420,"elapsed":30490,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"968483e9-f877-4d80-b1e3-575d90bb1df0"},"id":"CbKVAQgtnNKF","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","#assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"],"metadata":{"id":"IMTJI2Fi98h0"},"id":"IMTJI2Fi98h0","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#import torch_xla.core.xla_model as xm"],"metadata":{"id":"MbQztCxJKv78"},"id":"MbQztCxJKv78","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"152682d8","metadata":{"id":"152682d8"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.metrics import classification_report\n","from sklearn.utils.class_weight import compute_class_weight\n","import transformers\n","from transformers import BigBirdModel, BigBirdTokenizerFast\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel, BertTokenizerFast\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"]},{"cell_type":"code","execution_count":null,"id":"99ce5053","metadata":{"id":"99ce5053","executionInfo":{"status":"ok","timestamp":1683148682464,"user_tz":420,"elapsed":935,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2b05d5e5-b23f-47e3-db65-ef76b77c1727"},"outputs":[{"output_type":"stream","name":"stdout","text":["gpu available\n"]}],"source":["#device = xm.xla_device()\n","\n","#check is gpu is available\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","    print('gpu available')\n","else:\n","    device = torch.device('cpu')\n","    print('gpu not available')"]},{"cell_type":"markdown","source":["Our first attempt involved creating full transcripts for each case and exporting them as CSVs, which we then loaded into the script as needed. This exceeded the memory limits of Google Colab's TPUs and GPUs during training. \n","\n","We then tried a similar process but with the the \"utterance\" transcripts -- essentially lengths of text spoken by one person. Here, however, the RAM limit was exceeded when using the package that creates the utterance objects. We do not know why the RAM was exceeded here given that we were able to run the package locally on machines with lower amounts of RAM. \n","\n","Our third attempt was to create a dataframe of all utterances and the associated text and export it as a csv, roughly 1.7 million lines and 0.6GB as opposed to the packages ~7.3GB. "],"metadata":{"id":"oPYpREJfzyso"},"id":"oPYpREJfzyso"},{"cell_type":"code","source":["# set to run with utterances or conversations \n","utts = False"],"metadata":{"id":"R5w3dIS7Q3wH"},"id":"R5w3dIS7Q3wH","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create dataframe of utterances by case\n","df_utt = pd.read_csv('/content/drive/MyDrive/INFO251Final/Utterances_DataFrame.csv')\n","\n","# create dataframe by conversation record\n","df_convo = pd.read_csv('/content/drive/MyDrive/INFO251Final/Outcomes_NoTranscript.csv')\n","\n","# create dataframe of Martin Quinn scores to merge with dataframes\n","martin_quinn = pd.read_csv('/content/drive/MyDrive/INFO251Final/MartinQuinnScores.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2TNPMKAA1PQz","executionInfo":{"status":"ok","timestamp":1683149892695,"user_tz":420,"elapsed":14257,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"74d7f50f-7132-41db-f86d-e7be49b697f5"},"id":"2TNPMKAA1PQz","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-62-81bd520b1b86>:2: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df_utt = pd.read_csv('/content/drive/MyDrive/INFO251Final/Utterances_DataFrame.csv')\n"]}]},{"cell_type":"code","execution_count":null,"id":"c972caa7","metadata":{"id":"c972caa7"},"outputs":[],"source":["def clean_utts(df_utt):\n","    # updating columns\n","\n","    # rename columns\n","    df_utt = df_utt.rename(columns={'meta.votes_side': 'votes_side',\n","                                      'meta.win_side': 'win_side',\n","                                      'meta.case_id': 'case_id',\n","                                      'med': 'mq_score', \n","                                      'conversation_id': 'convo_id',\n","                                      'term_year': 'term'})\n","\n","    df_utt.term = df_utt.term.astype('int64')\n","\n","    # add MartinQuinn Scores\n","    df_utt = df_utt.merge(martin_quinn[['term', 'med']], on='term')\n","\n","    # drop unused columns\n","    # NOTE we may want to try an analysis on some of these later on\n","    df_utt = df_utt.drop(columns=['speaker', \n","                                  'reply_to', \n","                                  'timestamp', \n","                                  'meta.start_times', \n","                                  'meta.stop_times', \n","                                  'meta.speaker_type',\n","                                  'meta.side',\n","                                  'meta.timestamp',\n","                                  'vectors',\n","                                  'Unnamed: 0'])\n","\n","\n","    # add \"win_side\" to utterance dataframe\n","    df_utt = df_utt.merge(df_convo[['convo_id', 'win_side']], on='convo_id')\n","\n","    #df_utt.drop(columns=['Unnamed: 0'])\n","    df_utt = df_utt.rename(columns={'text': 'words'})\n","\n","    # Remove instances where case outcome was unknown or ????\n","    df_utt.drop(df_utt[df_utt['win_side'] == -1.0].index, inplace = True)\n","    df_utt.drop(df_utt[df_utt['win_side'] == 2.0].index, inplace = True)\n","\n","    # Remove null values from the few cases with incomplete data\n","    df_utt = df_utt.dropna()\n","\n","    return df_utt"]},{"cell_type":"code","source":["df_utt = clean_utts(df_utt)"],"metadata":{"id":"ik__eiZQKaV9"},"id":"ik__eiZQKaV9","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def clean_convos(df_convo):\n","  # Remove instances where case outcome was unknown or ????\n","  df_convo.drop(df_convo[df_convo['win_side'] == -1.0].index, inplace = True)\n","  df_convo.drop(df_convo[df_convo['win_side'] == 2.0].index, inplace = True)\n","\n","  # convert term from object to int\n","  df_convo.term = df_convo.term.astype('int64')\n","\n","  # drop unused columns\n","  # NOTE we may want to try an analysis on some of these later on. Save memory now\n","  df_convo = df_convo.drop(columns=['Unnamed: 0', 'vectors', 'advocates', 'votes_side'])\n","\n","  # 3 cases have null data due to oddities of transcribing data pre-digital transcripts\n","  df_convo = df_convo.dropna()\n","\n","  return df_convo"],"metadata":{"id":"67OjJ2aJKrRe"},"id":"67OjJ2aJKrRe","execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_convo = clean_convos(df_convo)"],"metadata":{"id":"5giNnmG7LWD-"},"id":"5giNnmG7LWD-","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"9fbecbdb","metadata":{"id":"9fbecbdb"},"outputs":[],"source":["df_test = df_convo.sample(n=600, replace=False, random_state=123)"]},{"cell_type":"code","source":["##### Delete for now\n","del(df_utt)"],"metadata":{"id":"67nzCYIP3rxV"},"id":"67nzCYIP3rxV","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"4d267fbd","metadata":{"id":"4d267fbd"},"outputs":[],"source":["# pull transcripts for each utterance or conversation and store in \"words\" column\n","# This method separately creates the transcripts for each conversation and stores them in a \n","# separate folder for reference. Although this allowed for easy grouping by case, it \n","# overwhelmed memory allocations \n","\n","def add_transcripts(df_test, n=1000, utts=False):\n","  for index, row in df_test.iterrows():\n","\n","\n","    if utts:\n","      folder_path = '/content/drive/MyDrive/INFO251Final/Trancripts_uttid_caseid/'\n","      read_path = folder_path+str(row['utt_id'])+'_'+str(row['case_id'])+'.txt'\n","\n","      transcript = open(read_path, 'r')\n","      text = transcript.read()\n","\n","      text = text[:n]\n","      df_test.loc[index, 'words'] = text\n","\n","      transcript.close()\n","\n","    else:\n","      folder_path = '/content/drive/MyDrive/INFO251Final/Trancripts_Case_Convo/'\n","      read_path = folder_path+str(row['convo_id'])+'_'+str(row['case_id'])+'.txt'\n","\n","      transcript = open(read_path, 'r')\n","      text = transcript.read()\n","\n","      text = text[:n]\n","\n","      df_test.at[index, 'words'] = text\n","  \n","      transcript.close()\n","\n","  return df_test\n","    "]},{"cell_type":"code","source":["df_test = add_transcripts(df_test)"],"metadata":{"id":"f81S4FOJOe8h"},"id":"f81S4FOJOe8h","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"35ed08d4","metadata":{"id":"35ed08d4"},"outputs":[],"source":["# convert to int for later reference by language models \n","df_test['win_side'] = df_test['win_side'].astype(int)"]},{"cell_type":"code","source":["df_test.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"rjiXn8IfO1I1","executionInfo":{"status":"ok","timestamp":1683150176120,"user_tz":420,"elapsed":34,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"d4168bf2-4df3-4eb7-9421-20ab1fe3f591"},"id":"rjiXn8IfO1I1","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           case_id  win_side  convo_id  term docket_id mq_score  \\\n","1037      1960_257         1     14377  1960       257    0.443   \n","1569      1963_615         1     14192  1963       615   -1.133   \n","1591      1963_116         0     14748  1963       116   -1.133   \n","7352   2012_10-930         1     23571  2012    10-930     0.24   \n","4413  1982_81-1020         1     19321  1982   81-1020    0.673   \n","\n","                                                  words  \n","1037  -- Chief Justice, members of the Court.\\nBefor...  \n","1569  Number 615, Escobedo, Petitioner, versus Illin...  \n","1591  -- Hostetter versus Idlewild Bon Voyage Liquor...  \n","7352  We'll hear argument first this morning in Case...  \n","4413  We will hear arguments first this morning in E...  "],"text/html":["\n","  <div id=\"df-755077cc-8c7f-4999-8b10-b0d97d4d7740\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>case_id</th>\n","      <th>win_side</th>\n","      <th>convo_id</th>\n","      <th>term</th>\n","      <th>docket_id</th>\n","      <th>mq_score</th>\n","      <th>words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1037</th>\n","      <td>1960_257</td>\n","      <td>1</td>\n","      <td>14377</td>\n","      <td>1960</td>\n","      <td>257</td>\n","      <td>0.443</td>\n","      <td>-- Chief Justice, members of the Court.\\nBefor...</td>\n","    </tr>\n","    <tr>\n","      <th>1569</th>\n","      <td>1963_615</td>\n","      <td>1</td>\n","      <td>14192</td>\n","      <td>1963</td>\n","      <td>615</td>\n","      <td>-1.133</td>\n","      <td>Number 615, Escobedo, Petitioner, versus Illin...</td>\n","    </tr>\n","    <tr>\n","      <th>1591</th>\n","      <td>1963_116</td>\n","      <td>0</td>\n","      <td>14748</td>\n","      <td>1963</td>\n","      <td>116</td>\n","      <td>-1.133</td>\n","      <td>-- Hostetter versus Idlewild Bon Voyage Liquor...</td>\n","    </tr>\n","    <tr>\n","      <th>7352</th>\n","      <td>2012_10-930</td>\n","      <td>1</td>\n","      <td>23571</td>\n","      <td>2012</td>\n","      <td>10-930</td>\n","      <td>0.24</td>\n","      <td>We'll hear argument first this morning in Case...</td>\n","    </tr>\n","    <tr>\n","      <th>4413</th>\n","      <td>1982_81-1020</td>\n","      <td>1</td>\n","      <td>19321</td>\n","      <td>1982</td>\n","      <td>81-1020</td>\n","      <td>0.673</td>\n","      <td>We will hear arguments first this morning in E...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-755077cc-8c7f-4999-8b10-b0d97d4d7740')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-755077cc-8c7f-4999-8b10-b0d97d4d7740 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-755077cc-8c7f-4999-8b10-b0d97d4d7740');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["import gc\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_PrUeVn3e2i_","executionInfo":{"status":"ok","timestamp":1683150176120,"user_tz":420,"elapsed":27,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"777f703e-9f5b-48c5-dbfe-af22cd8c904d"},"id":"_PrUeVn3e2i_","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["156"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["#### ONLY FOR UTTERANCES\n","# Run train test split with conversation grouping \n","\n","if utts:\n","  gss = GroupShuffleSplit(n_splits=1, train_size=0.7, random_state=123)"],"metadata":{"id":"o8kgeqbghqPn"},"id":"o8kgeqbghqPn","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create train and temp split. Temp split will be split in half into testing and validation sets\n","for train_idx, test_idx in gss.split(df_test, groups=df_test['convo_id']):\n","    train_df = df_test.iloc[train_idx]\n","    temp_df = df_test.iloc[test_idx]"],"metadata":{"id":"5CN_oX51h0u3","colab":{"base_uri":"https://localhost:8080/","height":215},"executionInfo":{"status":"error","timestamp":1683150224540,"user_tz":420,"elapsed":18,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"120e87e7-2843-4116-d6b1-a8700f7dcbbf"},"id":"5CN_oX51h0u3","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-76-3110927f64b8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create train and temp split. Temp split will be split in half into testing and validation sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'convo_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtemp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'gss' is not defined"]}]},{"cell_type":"code","source":["# split dataset into train, validation and test sets\n","train_text, temp_text, train_labels, temp_labels = train_test_split(df_test['words'], \n","                                                                    df_test['win_side'], \n","                                                                    random_state=123, \n","                                                                    test_size=0.3)\n","\n","\n","val_text, test_text, val_labels, test_labels = train_test_split(temp_text, \n","                                                                temp_labels, \n","                                                                random_state=123, \n","                                                                test_size=0.5)"],"metadata":{"id":"A12hUMpc_C7n"},"id":"A12hUMpc_C7n","execution_count":null,"outputs":[]},{"cell_type":"code","source":["%who"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GC5sdK_nkpKy","executionInfo":{"status":"ok","timestamp":1683150228771,"user_tz":420,"elapsed":15,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"b5b8b65c-4a2b-4121-f6e0-38a246be3128"},"id":"GC5sdK_nkpKy","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["AdamW\t AutoModel\t AutoModelForSequenceClassification\t AutoTokenizer\t BERT_Arch\t BertTokenizerFast\t BigBirdModel\t BigBirdTokenizerFast\t DataLoader\t \n","GroupShuffleSplit\t RandomSampler\t SequentialSampler\t TensorDataset\t add_transcripts\t batch_size\t best_valid_loss\t bigbird\t class_weights\t \n","classification_report\t clean_convos\t clean_utts\t compute_class_weight\t cross_entropy\t device\t df_convo\t df_test\t drive\t \n","epoch\t epochs\t evaluate\t gc\t martin_quinn\t nn\t np\t optimizer\t os\t \n","param\t path\t pd\t preds\t seq_len\t temp_labels\t temp_text\t test_labels\t test_mask\t \n","test_seq\t test_text\t test_y\t tokenizer\t tokens_test\t tokens_train\t tokens_val\t torch\t train\t \n","train_data\t train_dataloader\t train_labels\t train_loss\t train_losses\t train_mask\t train_sampler\t train_seq\t train_test_split\t \n","train_text\t train_y\t transformers\t utts\t val_data\t val_dataloader\t val_labels\t val_mask\t val_sampler\t \n","val_seq\t val_text\t val_y\t valid_loss\t valid_losses\t weights\t \n"]}]},{"cell_type":"code","source":["# delete older dfs to free up memory \n","del(df_convo, martin_quinn)"],"metadata":{"id":"qXT5hgy2kHpR"},"id":"qXT5hgy2kHpR","execution_count":null,"outputs":[]},{"cell_type":"code","source":["gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ibtNv7PKk1gO","executionInfo":{"status":"ok","timestamp":1683150248829,"user_tz":420,"elapsed":832,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"50c27808-8ef7-40a8-978b-ebcff8de188e"},"id":"ibtNv7PKk1gO","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","execution_count":null,"id":"89adcb50","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89adcb50","executionInfo":{"status":"ok","timestamp":1683150252227,"user_tz":420,"elapsed":2541,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"5c507eda-cd8f-4fcd-c07a-2bdb8d146af2"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["########################\n","# BigBird Model\n","# Load the BigBird model\n","bigbird = BigBirdModel.from_pretrained('google/bigbird-roberta-base')\n","\n","# Load the BigBird tokenizer\n","tokenizer = BigBirdTokenizerFast.from_pretrained('google/bigbird-roberta-base')\n","#########################\n","\n","\n","#########################\n","# BERT base model\n","# import BERT-base pretrained model\n","#bert = AutoModel.from_pretrained('bert-base-uncased')\n","\n","# Load the BERT tokenizer\n","#tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","#########################\n","\n","\n","# #########################\n","# # DeBERTa v3 base model\n","# Deberta = AutoModelForSequenceClassification.from_pretrained('microsoft/deberta-v3-base', num_labels=2)\n","\n","# # Load the DeBERTa v3 tokenizer\n","# tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base', model_max_length=512)\n","# #########################"]},{"cell_type":"code","execution_count":null,"id":"c7f52918","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"id":"c7f52918","executionInfo":{"status":"ok","timestamp":1683150252228,"user_tz":420,"elapsed":12,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"b98520f5-8192-421c-dc09-786edd59ae73"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Axes: >"]},"metadata":{},"execution_count":82},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# get length of all the messages in the train set\n","seq_len = [len(i.split()) for i in train_text]\n","\n","pd.Series(seq_len).hist()"]},{"cell_type":"code","source":[],"metadata":{"id":"_hWgefXWNBaO"},"id":"_hWgefXWNBaO","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The below cells exceed Google's RAM limits. The code above attempts to split tokenization up"],"metadata":{"id":"58KisfDzNJw0"},"id":"58KisfDzNJw0"},{"cell_type":"code","source":["# tokenize and encode sequences in the training set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    pad_to_max_length=True,\n","    truncation=True\n",")\n"],"metadata":{"id":"hQJN2Ej5M9aP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683150263541,"user_tz":420,"elapsed":743,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"489f3b11-e860-4218-e749-1a1e8e08d8f7"},"id":"hQJN2Ej5M9aP","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    pad_to_max_length=True,\n","    truncation=True\n",")"],"metadata":{"id":"VlHBgbSgM_W3"},"id":"VlHBgbSgM_W3","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"be0c5e89","metadata":{"id":"be0c5e89"},"outputs":[],"source":["# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    pad_to_max_length=True,\n","    truncation=True\n",")"]},{"cell_type":"code","execution_count":null,"id":"ad7b5fe7","metadata":{"id":"ad7b5fe7"},"outputs":[],"source":["## convert lists to tensors\n","\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"]},{"cell_type":"code","execution_count":null,"id":"8825f286","metadata":{"id":"8825f286"},"outputs":[],"source":["#define a batch size\n","batch_size = 32\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"id":"d91a93e5","metadata":{"id":"d91a93e5"},"outputs":[],"source":["# freeze all the parameters\n","\n","#original\n","#for param in bigbird.parameters():\n","   # param.requires_grad = False\n","#myswitch\n","for param in bigbird.parameters():\n","    param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"id":"6af2e1d7","metadata":{"id":"6af2e1d7"},"outputs":[],"source":["class BERT_Arch(nn.Module):\n","\n","    def __init__(self, bigbird):\n","        super(BERT_Arch, self).__init__()\n","        \n","        self.bigbird = bigbird \n","        \n","        # dropout layer\n","        self.dropout = nn.Dropout(0.5)\n","        \n","        # relu activation function\n","        self.relu =  nn.ReLU()\n","\n","        # dense layer 1\n","        self.fc1 = nn.Linear(768,512)\n","        \n","        # dense layer 2 (Output layer)\n","        self.fc2 = nn.Linear(512,2)\n","\n","        #softmax activation function\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask):\n","        \n","        #pass the inputs to the model  \n","        outputs = self.bigbird(sent_id, attention_mask=mask, return_dict=True, output_hidden_states=True)\n","        \n","        cls_hs = outputs['hidden_states'][-1][:, 0]\n","\n","        x = self.fc1(cls_hs)\n","\n","        x = self.relu(x)\n","\n","        x = self.dropout(x)\n","\n","        # output layer\n","        x = self.fc2(x)\n","        \n","        # apply softmax activation\n","        x = self.softmax(x)\n","\n","        return x\n"]},{"cell_type":"code","execution_count":null,"id":"9909837a","metadata":{"id":"9909837a"},"outputs":[],"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(bigbird)\n","\n","# push the model to GPU\n","model = model.to(device)"]},{"cell_type":"code","source":[],"metadata":{"id":"3RYQ5BU2XG79"},"id":"3RYQ5BU2XG79","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"952fba40","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"952fba40","executionInfo":{"status":"ok","timestamp":1683152176827,"user_tz":420,"elapsed":8,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"2bbbe560-fc84-4002-a8cd-b687332c6ce1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = AdamW(model.parameters(),lr = 1e-5, weight_decay=1e-3) "]},{"cell_type":"code","execution_count":null,"id":"3df15cfd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3df15cfd","executionInfo":{"status":"ok","timestamp":1683152179773,"user_tz":420,"elapsed":10,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"f56fabab-09be-411c-8a0d-22d9df25a20c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Class Weights: [1.51079137 0.74733096]\n"]}],"source":["# compute the class weights\n","class_weights = compute_class_weight('balanced', \n","                                     classes=np.unique(train_labels), \n","                                     y=train_labels)\n","\n","print(\"Class Weights:\",class_weights)"]},{"cell_type":"code","execution_count":null,"id":"7f26c12e","metadata":{"id":"7f26c12e"},"outputs":[],"source":["# converting list of class weights to a tensor\n","weights= torch.tensor(class_weights,dtype=torch.float)\n","\n","# push to GPU\n","weights = weights.to(device)\n","\n","# define the loss function\n","cross_entropy  = nn.NLLLoss(weight=weights) \n","\n","# number of training epochs\n","epochs = 5"]},{"cell_type":"code","execution_count":null,"id":"e8af0312","metadata":{"id":"e8af0312"},"outputs":[],"source":["# function to train the model\n","def train():\n","    \n","    model.train()\n","    total_loss, total_accuracy = 0, 0\n","    \n","    # empty list to save model predictions\n","    total_preds=[]\n","    \n","    # iterate over batches\n","    for step, batch in enumerate(train_dataloader):\n","        \n","        # progress update after every 50 batches.\n","        if step % 50 == 0 and not step == 0:\n","            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","        \n","        # push the batch to gpu\n","        batch = [r.to(device) for r in batch]\n","        \n","        sent_id, mask, labels = batch\n","        \n","        # clear previously calculated gradients \n","        model.zero_grad()        \n","\n","        # get model predictions for the current batch\n","        preds = model(sent_id, mask)\n","\n","        # compute the loss between actual and predicted values\n","        loss = cross_entropy(preds, labels)\n","\n","        # add on to the total loss\n","        total_loss = total_loss + loss.item()\n","\n","        # backward pass to calculate the gradients\n","        loss.backward()\n","\n","        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # update parameters\n","        optimizer.step()\n","\n","        # model predictions are stored on GPU. So, push it to CPU\n","        preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","\n","    # compute the training loss of the epoch\n","    avg_loss = total_loss / len(train_dataloader)\n","    \n","    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","      # reshape the predictions in form of (number of samples, no. of classes)\n","    total_preds  = np.concatenate(total_preds, axis=0)\n","\n","    #returns the loss and predictions\n","    return avg_loss, total_preds"]},{"cell_type":"code","execution_count":null,"id":"14ca26a9","metadata":{"id":"14ca26a9"},"outputs":[],"source":["# function for evaluating the model\n","def evaluate():\n","    \n","    print(\"\\nEvaluating...\")\n","    \n","    # deactivate dropout layers\n","    model.eval()\n","\n","    total_loss, total_accuracy = 0, 0\n","    \n","    # empty list to save the model predictions\n","    total_preds = []\n","\n","    # iterate over batches\n","    for step,batch in enumerate(val_dataloader):\n","        \n","        # Progress update every 25 batches.\n","        if step % 25 == 0 and not step == 0:\n","            \n","            # Calculate elapsed time in minutes.\n","            #Issue here so I commented out\n","            #elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","        # push the batch to gpu\n","        batch = [t.to(device) for t in batch]\n","\n","        sent_id, mask, labels = batch\n","\n","        # deactivate autograd\n","        with torch.no_grad():\n","            \n","            # model predictions\n","            preds = model(sent_id, mask)\n","\n","            # compute the validation loss between actual and predicted values\n","            loss = cross_entropy(preds,labels)\n","\n","            total_loss = total_loss + loss.item()\n","\n","            preds = preds.detach().cpu().numpy()\n","\n","            total_preds.append(preds)\n","\n","    # compute the validation loss of the epoch\n","    avg_loss = total_loss / len(val_dataloader) \n","\n","    # reshape the predictions in form of (number of samples, no. of classes)\n","    total_preds  = np.concatenate(total_preds, axis=0)\n","\n","    return avg_loss, total_preds"]},{"cell_type":"code","execution_count":null,"id":"9504517a","metadata":{"id":"9504517a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683152226186,"user_tz":420,"elapsed":16,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"22d6aaea-998d-41aa-cfb6-b1649521fbad"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["47"]},"metadata":{},"execution_count":118}],"source":["# import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"id":"160739aa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"160739aa","outputId":"75b58164-b5c5-4681-c913-288ec3eb212a","executionInfo":{"status":"ok","timestamp":1683152275404,"user_tz":420,"elapsed":49224,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Epoch 1 / 5\n","\n","Evaluating...\n","\n","Training Loss: 0.701\n","Validation Loss: 0.703\n","\n"," Epoch 2 / 5\n","\n","Evaluating...\n","\n","Training Loss: 0.701\n","Validation Loss: 0.701\n","\n"," Epoch 3 / 5\n","\n","Evaluating...\n","\n","Training Loss: 0.708\n","Validation Loss: 0.699\n","\n"," Epoch 4 / 5\n","\n","Evaluating...\n","\n","Training Loss: 0.699\n","Validation Loss: 0.698\n","\n"," Epoch 5 / 5\n","\n","Evaluating...\n","\n","Training Loss: 0.694\n","Validation Loss: 0.697\n"]}],"source":["# set initial loss to infinite\n","best_valid_loss = float('16')\n","\n","# empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","#for each epoch\n","for epoch in range(epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss, _ = train()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'saved_weights.pt')\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    \n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"]},{"cell_type":"code","execution_count":null,"id":"ac748690","metadata":{"id":"ac748690","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683152279188,"user_tz":420,"elapsed":1125,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"46b43630-cac8-4ed4-a5d5-b944b44fba2a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":120}],"source":["#load weights of best model\n","path = 'saved_weights.pt'\n","model.load_state_dict(torch.load(path))"]},{"cell_type":"code","execution_count":null,"id":"6fd02379","metadata":{"id":"6fd02379"},"outputs":[],"source":["# get predictions for test data\n","with torch.no_grad():\n","    preds = model(test_seq.to(device), test_mask.to(device))\n","    preds = preds.detach().cpu().numpy()"]},{"cell_type":"code","execution_count":null,"id":"c9628385","metadata":{"id":"c9628385","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683152284228,"user_tz":420,"elapsed":342,"user":{"displayName":"Quinn Wilson","userId":"02612196500204887187"}},"outputId":"b7df4e36-300b-411f-a123-ffcca6f48c93"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.43      0.95      0.59        37\n","           1       0.78      0.13      0.23        53\n","\n","    accuracy                           0.47        90\n","   macro avg       0.60      0.54      0.41        90\n","weighted avg       0.64      0.47      0.38        90\n","\n"]}],"source":["# model's performance\n","preds = np.argmax(preds, axis = 1)\n","print(classification_report(test_y, preds))"]},{"cell_type":"code","execution_count":null,"id":"1d8bb1e8","metadata":{"id":"1d8bb1e8"},"outputs":[],"source":["preds"]},{"cell_type":"code","execution_count":null,"id":"44cde729","metadata":{"id":"44cde729"},"outputs":[],"source":["del(model)\n","torch.cuda.empty_cache()"]},{"cell_type":"code","source":[],"metadata":{"id":"5DxX0eyFjDUV"},"id":"5DxX0eyFjDUV","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[]},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}